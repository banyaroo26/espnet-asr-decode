{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-16T11:42:37.463795Z",
     "start_time": "2025-08-16T11:42:37.447716Z"
    }
   },
   "source": [
    "import sys\n",
    "import espnet\n",
    "from espnet2.bin.asr_inference_streaming import Speech2TextStreaming\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "import argparse\n",
    "import numpy as np\n",
    "import wave\n",
    "import pyaudio\n",
    "import os\n",
    "import gradio as gr"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:49:58.532848Z",
     "start_time": "2025-08-16T11:48:59.089514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tag        = \"D-Keqi/espnet_asr_train_asr_streaming_transformer_raw_en_bpe500_sp_valid.acc.ave\"\n",
    "d          = ModelDownloader()\n",
    "model_info = d.download_and_unpack(tag)\n",
    "\n",
    "# Initialize streaming ASR\n",
    "speech2text = Speech2TextStreaming(\n",
    "    **model_info,\n",
    "    token_type=\"bpe\",\n",
    "    maxlenratio=0.0,\n",
    "    minlenratio=0.0,\n",
    "    beam_size=5,          # Faster streaming\n",
    "    ctc_weight=0.7,       # Hybrid CTC/attention\n",
    "    lm_weight=0.3,        # No external LM\n",
    "    penalty=0.0,\n",
    "    nbest=1,\n",
    "    device=\"cpu\",        # Use GPU if available\n",
    "    disable_repetition_detection=True,  # Avoid stuck loops\n",
    ")\n",
    "\n",
    "print('recording ........')\n",
    "\n",
    "CHUNK    = 5120 # 2048 5120\n",
    "FORMAT   = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE     = 16000 # 16000\n",
    "\n",
    "# Time per chunk\n",
    "# ms = (chunk/rate) * 1000\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "'''\n",
    "rate=RATE: Sampling rate in Hz (e.g., 44100 means 44100 samples per second).\n",
    "How many samples captured per second\n",
    "frames_per_buffer=CHUNK: How many audio samples per chunk are processed at a time.\n",
    "A typical value is 1024.\n",
    "\n",
    "input=True: Specifies that this is an input stream (microphone).\n",
    "channels=CHANNELS: Number of audio channels (e.g., 1 for mono, 2 for stereo).\n",
    "format=FORMAT: Specifies the data type (e.g., pyaudio.paInt16 for 16-bit integers)\n",
    "'''\n",
    "\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "'''\n",
    "RATE/CHUNK = chunks per second\n",
    "* RECORD_SECONDS = total chunks\n",
    "'''\n",
    "\n",
    "CHUNKS_PER_SECOND = int(RATE/CHUNK)\n",
    "CUT_AT_CHUNK = CHUNKS_PER_SECOND * 10\n",
    "\n",
    "################\n",
    "BUFFERED_CHUNKS = 15\n",
    "# Audio buffer to store recent chunks\n",
    "audio_buffer = []\n",
    "\n",
    "chunk_counter = 0\n",
    "final_flag = False\n",
    "\n",
    "# TOTAL_CHUNKS = int((RATE/CHUNK)*RECORD_SECONDS) + 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    ''' for each chunk '''\n",
    "\n",
    "    data = stream.read(CHUNK) # for each loop, reading chunk size samples (blocking)\n",
    "\n",
    "    data = np.frombuffer(data, dtype='int16') # builds numpy array from buffer-like object\n",
    "\n",
    "    data_for_vad = data.astype(np.float32)/32767.0\n",
    "\n",
    "    data = data.astype(np.float16)/32767.0 # normalize data as float\n",
    "\n",
    "    ##############\n",
    "    # Store current chunk in buffer (for overlap)\n",
    "    audio_buffer.append(data)\n",
    "    if len(audio_buffer) > BUFFERED_CHUNKS:\n",
    "        audio_buffer.pop(0)  # Remove oldest chunk\n",
    "\n",
    "    chunk_counter += 1\n",
    "\n",
    "    '''\n",
    "    results = [\n",
    "        # a list of tuples because of multiple alternative transcriptions\n",
    "        but here nbest=1 during initialization so only one tuple will be returned\n",
    "        (\n",
    "            'text' - The recognized transcription as a string\n",
    "            'token' - The tokenized representation of the recognized text (a list of chars)\n",
    "            'token_int' - The token IDs (integer representation of tokens)\n",
    "            'hypothesis object' - The full decoding hypothesis object that contains additional detailed information about the recognition process and scores\n",
    "        )\n",
    "    ]\n",
    "    '''\n",
    "\n",
    "    ############## FROM DEEPSEEK\n",
    "    # Check if cutoff reached\n",
    "    if chunk_counter >= CUT_AT_CHUNK:\n",
    "        chunk_counter = 0\n",
    "        final_flag = True\n",
    "\n",
    "        # Process current chunk + buffered chunks\n",
    "        combined_audio = np.concatenate(audio_buffer) if audio_buffer else data\n",
    "        results = speech2text(speech=combined_audio, is_final=final_flag)\n",
    "\n",
    "        # Reset but keep buffer for next iteration\n",
    "        speech2text.reset()\n",
    "        audio_buffer = audio_buffer[-BUFFERED_CHUNKS:]  # Retain last N chunks\n",
    "    else:\n",
    "        final_flag = False\n",
    "        results = speech2text(speech=data, is_final=final_flag)\n",
    "\n",
    "    # Print results\n",
    "    if results and results[0][0]:\n",
    "        print(results[0][0])\n",
    "    #################"
   ],
   "id": "5859074113846c70",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 32 files: 100%|██████████| 32/32 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording ........\n",
      "of the cla\n",
      "of the cla\n",
      "of the clas\n",
      "of the clas\n",
      "of the class i start\n",
      "of the class i start to feel sc\n",
      "of the class i start to feel sc\n",
      "of the class i start to feel scared\n",
      "of the class i start to feel scared\n",
      "of the class i start to feel scared\n",
      "of the class i start to feel scared\n",
      "of the class i start to feel scared\n",
      "of the class i start to feel scared my hand\n",
      "of the class i start to feel scared my hand shak\n",
      "of the class i start to feel scared my hand shak\n",
      "of the class i start to feel scared my hand shake\n",
      "of the class i start to feel scared my hand shake and my vo\n",
      "of the class i start to feel scared my hand shake and my vo\n",
      "of the class i start to feel scared my hand shake and my voice become\n",
      "of the class i start to feel scared my hand shake and my voice become\n",
      "of the class i start to feel scared my hand shake and my voice becomes by it\n",
      "of the class i start to feel scared my hand shake and my voice becomes by it\n",
      "of the class i start to feel scared my hand shake and my voice becomes by it\n",
      "of the class i start to feel scared my hand shake and my voice becomes by it\n",
      "of the class i start to feel scared my hands shake and my voice becomes by it i worried that i will messak and my voice becomes by it i worried that i will miss\n",
      "or forget\n",
      "or forget\n",
      "or forget but\n",
      "or forget but\n",
      "or forget but it is di\n",
      "or forget but it is difficult to\n",
      "or forget but it is difficult to\n",
      "or forget but it is difficult to overc\n",
      "or forget but it is difficult to overcome my f\n",
      "or forget but it is difficult to overcome my f\n",
      "or forget but it is difficult to overcome my fear\n",
      "or forget but it is difficult to overcome my fear\n",
      "or forget but it is difficult to overcome my fear\n",
      "or forget but it is difficult to overcome my fear some\n",
      "or forget but it is difficult to overcome my fear some\n",
      "or forget but it is difficult to overcome my fear sometimes i\n",
      "or forget but it is difficult to overcome my fear sometimes i try to\n",
      "or forget but it is difficult to overcome my fear sometimes i try to\n",
      "or forget but it is difficult to overcome my fear sometimes i try to imagine\n",
      "or forget but it is difficult to overcome my fear sometimes i try to imagine\n",
      "or forget but it is difficult to overcome my fear sometimes i try to imagine\n",
      "or forget but it is difficult to overcome my fear sometimes i tried to imagine that i have\n",
      "or forget but it is difficult to overcome my fear sometimes i tried to imagine that i have\n",
      "or forget but it is difficult to overcome my fear sometimes i tried to imagine that i have taught to\n",
      "or forget but it is difficult to overcome my fear sometimes i tried to imagine that i am taught to my friends sometimes i try to imagine that i am taught to my friends and\n",
      "helps english\n",
      "helped english present\n",
      "helped english present\n",
      "helped english presentation\n",
      "helped english presentation\n",
      "helped english presentation\n",
      "helped english presentation\n",
      "helped english presentation\n",
      "helped english presentation i am very\n",
      "helped english presentation i am very nervous\n",
      "helped english presentation i am very nervous\n",
      "helped english presentation i am very nervous about\n",
      "helped english presentation i am very nervous about giving an en\n",
      "helped english presentation i am very nervous about giving an en\n",
      "helped english presentation i am very nervous about giving an english pre\n",
      "helped english presentation i am very nervous about giving an english pre\n",
      "helped english presentation i am very nervous about giving an english present\n",
      "helped english presentation i am very nervous about giving an english present\n",
      "helped english presentation i am very nervous about giving an english present\n",
      "helped english presentation i am very nervous about giving an english presentation after\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 104\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;66;03m# Process current chunk + buffered chunks\u001B[39;00m\n\u001B[0;32m    103\u001B[0m combined_audio \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(audio_buffer) \u001B[38;5;28;01mif\u001B[39;00m audio_buffer \u001B[38;5;28;01melse\u001B[39;00m data\n\u001B[1;32m--> 104\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mspeech2text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspeech\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcombined_audio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_final\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfinal_flag\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;66;03m# Reset but keep buffer for next iteration\u001B[39;00m\n\u001B[0;32m    107\u001B[0m speech2text\u001B[38;5;241m.\u001B[39mreset()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\espnet2\\bin\\asr_inference_streaming.py:323\u001B[0m, in \u001B[0;36mSpeech2TextStreaming.__call__\u001B[1;34m(self, speech, is_final)\u001B[0m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feats \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    316\u001B[0m     enc, _, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masr_model\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[0;32m    317\u001B[0m         feats,\n\u001B[0;32m    318\u001B[0m         feats_lengths,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    321\u001B[0m         infer_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 323\u001B[0m     nbest_hyps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeam_search(\n\u001B[0;32m    324\u001B[0m         x\u001B[38;5;241m=\u001B[39menc[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    325\u001B[0m         maxlenratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxlenratio,\n\u001B[0;32m    326\u001B[0m         minlenratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mminlenratio,\n\u001B[0;32m    327\u001B[0m         is_final\u001B[38;5;241m=\u001B[39mis_final,\n\u001B[0;32m    328\u001B[0m     )\n\u001B[0;32m    329\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massemble_hyps(nbest_hyps)\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\espnet\\nets\\batch_beam_search_online.py:344\u001B[0m, in \u001B[0;36mBatchBeamSearchOnline.forward\u001B[1;34m(self, x, maxlenratio, minlenratio, is_final)\u001B[0m\n\u001B[0;32m    340\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_one_block_time_sync(\n\u001B[0;32m    341\u001B[0m         h, block_is_final, maxlen, maxlenratio\n\u001B[0;32m    342\u001B[0m     )\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 344\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_one_block\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    345\u001B[0m \u001B[43m        \u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblock_is_final\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxlen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminlen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxlenratio\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    347\u001B[0m logging\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinished processing block: \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_block)\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_block \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\espnet\\nets\\batch_beam_search_online.py:397\u001B[0m, in \u001B[0;36mBatchBeamSearchOnline.process_one_block\u001B[1;34m(self, h, is_final, maxlen, minlen, maxlenratio)\u001B[0m\n\u001B[0;32m    395\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_idx \u001B[38;5;241m<\u001B[39m maxlen:\n\u001B[0;32m    396\u001B[0m     logging\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mposition \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_idx))\n\u001B[1;32m--> 397\u001B[0m     best \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_hyps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    399\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_idx \u001B[38;5;241m==\u001B[39m maxlen \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    400\u001B[0m         \u001B[38;5;66;03m# end decoding\u001B[39;00m\n\u001B[0;32m    401\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_hyps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_process(\n\u001B[0;32m    402\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_idx, maxlen, minlen, maxlenratio, best, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mended_hyps\n\u001B[0;32m    403\u001B[0m         )\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\espnet\\nets\\batch_beam_search.py:312\u001B[0m, in \u001B[0;36mBatchBeamSearch.search\u001B[1;34m(self, running_hyps, x, pre_x)\u001B[0m\n\u001B[0;32m    308\u001B[0m     part_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtopk(pre_beam_scores, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_beam_size, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# NOTE(takaaki-hori): Unlike BeamSearch, we assume that score_partial returns\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;66;03m# full-size score matrices, which has non-zero scores for part_ids and zeros\u001B[39;00m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# for others.\u001B[39;00m\n\u001B[1;32m--> 312\u001B[0m part_scores, part_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore_partial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrunning_hyps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpart_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpart_scorers:\n\u001B[0;32m    314\u001B[0m     weighted_scores \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights[k] \u001B[38;5;241m*\u001B[39m part_scores[k]\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\espnet\\nets\\batch_beam_search.py:233\u001B[0m, in \u001B[0;36mBatchBeamSearch.score_partial\u001B[1;34m(self, hyp, ids, x, pre_x)\u001B[0m\n\u001B[0;32m    229\u001B[0m         scores[k], states[k] \u001B[38;5;241m=\u001B[39m d\u001B[38;5;241m.\u001B[39mbatch_score_partial(\n\u001B[0;32m    230\u001B[0m             hyp\u001B[38;5;241m.\u001B[39myseq, ids, hyp\u001B[38;5;241m.\u001B[39mstates[k], pre_x\n\u001B[0;32m    231\u001B[0m         )\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 233\u001B[0m         scores[k], states[k] \u001B[38;5;241m=\u001B[39m \u001B[43md\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_score_partial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhyp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43myseq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstates\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scores, states\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\espnet\\nets\\scorers\\ctc.py:126\u001B[0m, in \u001B[0;36mCTCPrefixScorer.batch_score_partial\u001B[1;34m(self, y, ids, state, x)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Score new token.\u001B[39;00m\n\u001B[0;32m    103\u001B[0m \n\u001B[0;32m    104\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    114\u001B[0m \n\u001B[0;32m    115\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    116\u001B[0m batch_state \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    117\u001B[0m     (\n\u001B[0;32m    118\u001B[0m         torch\u001B[38;5;241m.\u001B[39mstack([s[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m state], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    125\u001B[0m )\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mids\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Realtime_ASR\\.venv\\lib\\site-packages\\espnet\\nets\\ctc_prefix_score.py:160\u001B[0m, in \u001B[0;36mCTCPrefixScoreTH.__call__\u001B[1;34m(self, y, state, scoring_ids, att_w)\u001B[0m\n\u001B[0;32m    156\u001B[0m     rp \u001B[38;5;241m=\u001B[39m r[t \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    157\u001B[0m     rr \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([rp[\u001B[38;5;241m0\u001B[39m], log_phi[t \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m], rp[\u001B[38;5;241m0\u001B[39m], rp[\u001B[38;5;241m1\u001B[39m]])\u001B[38;5;241m.\u001B[39mview(\n\u001B[0;32m    158\u001B[0m         \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m, n_bh, snum\n\u001B[0;32m    159\u001B[0m     )\n\u001B[1;32m--> 160\u001B[0m     \u001B[43mr\u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlogsumexp(rr, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m+\u001B[39m x_[:, t]\n\u001B[0;32m    162\u001B[0m \u001B[38;5;66;03m# compute log prefix probabilities log(psi)\u001B[39;00m\n\u001B[0;32m    163\u001B[0m log_phi_x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((log_phi[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m), log_phi[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m+\u001B[39m x_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
